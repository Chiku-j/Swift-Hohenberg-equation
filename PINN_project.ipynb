{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PINN_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyDOE"
      ],
      "metadata": {
        "id": "cMqEPqr3RK35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca6b8d4-7fe7-47ae-ff24-128597732d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9WkhEeWRI0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c63bac-78c1-46a7-b761-62d767f01f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=40, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=40, out_features=40, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=40, out_features=40, bias=True)\n",
            "  (5): Tanh()\n",
            "  (6): Linear(in_features=40, out_features=40, bias=True)\n",
            "  (7): Tanh()\n",
            "  (8): Linear(in_features=40, out_features=40, bias=True)\n",
            "  (9): Tanh()\n",
            "  (10): Linear(in_features=40, out_features=1, bias=True)\n",
            ")\n",
            "model parameters on gpu: False\n",
            "Epoch (Adam): 0, Cost: 0.01746806502342224\n",
            "Epoch (Adam): 100, Cost: 0.00018169693066738546\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from pyDOE import lhs\n",
        "from physicsinformed_1D import PhysicsInformedContinuous\n",
        "from scipy.interpolate import griddata\n",
        "import utilities_1D\n",
        "\n",
        "# Select gpu if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.float\n",
        "\n",
        "# Set seed for the Random Number Generator (RNG), setting the seed generates same set of random numbers everytime \n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0) \n",
        "\n",
        "# Define no. of training points\n",
        "N0 = 100\n",
        "N_b = 50\n",
        "N_f = 20000\n",
        "\n",
        "# Define feed-forward network architecture\n",
        "layers = [2, 40, 40, 40, 40, 40, 1]\n",
        "\n",
        "# Define no. of epochs for each optimizer\n",
        "epochs_Adam = 200\n",
        "epochs_LBFGS = 100\n",
        "\n",
        "### PRE-PROCESSING ###\n",
        "# Loading benchmark data\n",
        "data = scipy.io.loadmat('1D_datapoints.mat')\n",
        "t = data['t'].flatten()[:, None]\n",
        "x = data['x'].flatten()[:, None]\n",
        "u_sol = data['u'].T\n",
        "\n",
        "X, T = np.meshgrid(x, t) # Creates mesh such that for every xi, all the ti s can be accessed and vice-versa\n",
        "\n",
        "# Transform grid into vectors that can be processed by the neural net\n",
        "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None])) #Stack arrays in sequence horizontally (column wise)\n",
        "u_star = u_sol.flatten()[:, None]\n",
        "\n",
        "# Domain bounds\n",
        "lb = X_star.min(0)\n",
        "ub = X_star.max(0)\n",
        "\n",
        "# Select random data points for the initial condition\n",
        "idx_x = np.random.choice(x.shape[0], N0, replace=False) # Choose random 100 indices from 256 total indices of space\n",
        "x0 = x[idx_x, :] # location of these 100 random points\n",
        "u0 = torch.tensor(u_sol.T[idx_x, 0:1], dtype=dtype, device=device) # Choose temperatures of 100 random points at t=0\n",
        "\n",
        "# Select random data points for the boundary condition\n",
        "idx_t = np.random.choice(t.shape[0], N_b, replace=False) # Choose random 50 indices from 201 total indices of time\n",
        "tb = t[idx_t, :] # time stamps of those 50 indices\n",
        "\n",
        "# Create collocation points with latin hypercube sampling\n",
        "X_f = lb + (ub - lb) * lhs(2, N_f) # Creates 20000 sample points in both x and t\n",
        "\n",
        "X0 = np.concatenate((x0, 0 * x0), 1) # (x0, 0)\n",
        "X_lb = np.concatenate((0 * tb + lb[0], tb), 1) # (lb[0], tb)\n",
        "X_ub = np.concatenate((0 * tb + ub[0], tb), 1) # (ub[0], tb)\n",
        "\n",
        "### TRAINING ###\n",
        "# Create torch.tensors of training data\n",
        "x0 = torch.tensor(X0[:, 0:1], dtype=dtype, requires_grad=True, device=device)\n",
        "t0 = torch.tensor(X0[:, 1:2], dtype=dtype, requires_grad=True, device=device)\n",
        "\n",
        "x_lb = torch.tensor(X_lb[:, 0:1], dtype=dtype, requires_grad=True, device=device)\n",
        "t_lb = torch.tensor(X_lb[:, 1:2], dtype=dtype, requires_grad=True, device=device)\n",
        "\n",
        "x_ub = torch.tensor(X_ub[:, 0:1], dtype=dtype, requires_grad=True, device=device)\n",
        "t_ub = torch.tensor(X_ub[:, 1:2], dtype=dtype, requires_grad=True, device=device)\n",
        "\n",
        "x_f = torch.tensor(X_f[:, 0:1], dtype=dtype, requires_grad=True, device=device)\n",
        "t_f = torch.tensor(X_f[:, 1:2], dtype=dtype, requires_grad=True, device=device)\n",
        "\n",
        "# Initialize PINN model\n",
        "PINNModel = PhysicsInformedContinuous(layers, t0, x0, t_lb, x_lb, t_ub, x_ub, t_f, x_f, u0)\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "PINNModel.train(epochs_Adam, optimizer='Adam', lr=0.001)\n",
        "#PINNModel.train(epochs_LBFGS, optimizer='L-BFGS')\n",
        "elapsed = time.time() - start_time\n",
        "print('Training time: %.4f' % (elapsed))\n",
        "\n",
        "# Create torch.tensors to predict solution for the whole domain\n",
        "x_star = torch.tensor(X_star[:, 0:1], dtype=dtype, requires_grad=True, device=device)\n",
        "t_star = torch.tensor(X_star[:, 1:2], dtype=dtype, requires_grad=False, device=device)\n",
        "\n",
        "# Predict temperature distribution and first derivative for the heat flux\n",
        "u_pred = PINNModel.u_nn(t_star, x_star)\n",
        "u_x_pred = utilities_1D.get_derivative(u_pred, x_star, 1)\n",
        "\n",
        "### POST-PROCESSING ###\n",
        "u_pred = u_pred.detach().cpu().numpy()\n",
        "u_x_pred = u_x_pred.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "# Compute error measure\n",
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "print('Error u: %e' % (error_u))\n",
        "\n",
        "u_pred_grid = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "error_u_abs = np.abs(u_sol - u_pred_grid)\n",
        "\n",
        "X_u_train = np.vstack([X0, X_lb, X_ub])\n",
        "utilities_1D.plot_results(t, x, u_pred_grid, u_sol, X_u_train, lb, ub)\n",
        "\n",
        "# Plot training history and predicitons\n",
        "PINNModel.plot_training_history()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uO79tUnzLHes"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}